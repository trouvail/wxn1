{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 机器学习作业二\n",
    "- 姓名：周延霖\n",
    "- 学号：2013921\n",
    "- 专业：信息安全"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验要求\n",
    "题目：回归模型  \n",
    "实验简介：\n",
    "- 回归是监督学习的一个重要问题，回归用于预测**输入变量**和**输出变量**之间的关系，特别是当输入变量的值发生变化时，输出变量的值也随之发生变化。\n",
    "- 回归模型是一种表示从输入变量到输出变量之间映射的函数\n",
    "- 对连续值的预测\n",
    "- 可以用合适的曲线揭示样本点随着自变量的变化关系\n",
    "实验要求：\n",
    "1. 基本要求：\n",
    "    - 将数据集winequality-white.csv按照4:1划分为训练集和测试集。  \n",
    "        1. 构造线性回归模型，并采用批量梯度下降和随机梯度下降进行优化；输出训练集和测试集的均方误差（MSE），画出MSE收敛曲线。       \n",
    "        2. 对于批量梯度下降和随机梯度下降，采用不同的学习率并进行MSE曲线展示，分析选择最佳的学习率。\n",
    "    - 特别需要注意：\n",
    "        - 划分数据集时尽可能保持数据分布的一致性，保持样本类别比例相似，可采用分层采样的方式。\n",
    "        - 需要对数据集进行一定的预处理\n",
    "2. 中级要求：\n",
    "    - 探究回归模型在机器学习和统计学上的差异。\n",
    "        - 回归模型在机器学习领域和统计学领域中都十分常用，而且使用方法也相似，但其实际的含义具有本质的区别。我们希望同学们从回归模型的角度更加充分地理解机器学习和统计学的区别。\n",
    "3. 高级要求：\n",
    "    - 编程实现岭回归算法，求解训练样本的岭回归模型，平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法均可）。\n",
    "\n",
    "**截止日期：10月21日**\n",
    "- 以.ipynb形式的文件提交，输出运行结果，并确保自己的代码能够正确运行\n",
    "- 发送到邮箱：2120220594@mail.nankai.edu.cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import csv\n",
    "import operator\n",
    "import random\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集 semesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入数据\n",
    "# data数据尚未进行预处理\n",
    "data = pd.read_csv(\"winequality-white.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "# 中心化代码\n",
    "def Normalization_fun(x):\n",
    "    # 特征零均值\n",
    "    x = (x - np.mean(x, 0)) / (np.max(x, 0) - np.min(x, 0))\n",
    "    return x\n",
    "\n",
    "# 提取特征和标签\n",
    "X = data.iloc[:, 0:-1]  # N D\n",
    "X = Normalization_fun(X)\n",
    "Y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 可视化中心化后的sulphates特征\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(X[\"sulphates\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013963</td>\n",
       "      <td>-0.008080</td>\n",
       "      <td>0.015547</td>\n",
       "      <td>0.219457</td>\n",
       "      <td>-0.002292</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.134425</td>\n",
       "      <td>-0.171151</td>\n",
       "      <td>-0.046334</td>\n",
       "      <td>-0.276495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.053345</td>\n",
       "      <td>0.021332</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>-0.073488</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>-0.074244</td>\n",
       "      <td>-0.014758</td>\n",
       "      <td>-0.000528</td>\n",
       "      <td>0.101576</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-0.163591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.119732</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.039644</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.018495</td>\n",
       "      <td>-0.095964</td>\n",
       "      <td>0.020679</td>\n",
       "      <td>0.065212</td>\n",
       "      <td>-0.057961</td>\n",
       "      <td>-0.066817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033193</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>-0.008549</td>\n",
       "      <td>0.032340</td>\n",
       "      <td>0.036284</td>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>-0.104473</td>\n",
       "      <td>-0.099075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033193</td>\n",
       "      <td>-0.047295</td>\n",
       "      <td>-0.008549</td>\n",
       "      <td>0.032340</td>\n",
       "      <td>0.036284</td>\n",
       "      <td>0.040738</td>\n",
       "      <td>0.110532</td>\n",
       "      <td>0.030319</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>-0.104473</td>\n",
       "      <td>-0.099075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.062960</td>\n",
       "      <td>-0.066903</td>\n",
       "      <td>-0.026621</td>\n",
       "      <td>-0.073488</td>\n",
       "      <td>-0.020096</td>\n",
       "      <td>-0.039401</td>\n",
       "      <td>-0.107565</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>0.074303</td>\n",
       "      <td>0.011806</td>\n",
       "      <td>0.110602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.024499</td>\n",
       "      <td>0.040940</td>\n",
       "      <td>0.015547</td>\n",
       "      <td>0.024672</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>0.075582</td>\n",
       "      <td>0.068769</td>\n",
       "      <td>0.016823</td>\n",
       "      <td>-0.034788</td>\n",
       "      <td>-0.034706</td>\n",
       "      <td>-0.147462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.034114</td>\n",
       "      <td>-0.037491</td>\n",
       "      <td>-0.086862</td>\n",
       "      <td>-0.079623</td>\n",
       "      <td>-0.014161</td>\n",
       "      <td>-0.018495</td>\n",
       "      <td>-0.063482</td>\n",
       "      <td>-0.028675</td>\n",
       "      <td>-0.180242</td>\n",
       "      <td>-0.034706</td>\n",
       "      <td>-0.179720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.130268</td>\n",
       "      <td>0.011528</td>\n",
       "      <td>-0.020597</td>\n",
       "      <td>-0.081157</td>\n",
       "      <td>-0.070541</td>\n",
       "      <td>-0.053338</td>\n",
       "      <td>-0.065802</td>\n",
       "      <td>-0.102899</td>\n",
       "      <td>0.137939</td>\n",
       "      <td>-0.127729</td>\n",
       "      <td>0.368667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.082191</td>\n",
       "      <td>-0.066903</td>\n",
       "      <td>0.027595</td>\n",
       "      <td>-0.085758</td>\n",
       "      <td>-0.076476</td>\n",
       "      <td>-0.046370</td>\n",
       "      <td>-0.093644</td>\n",
       "      <td>-0.089018</td>\n",
       "      <td>0.065212</td>\n",
       "      <td>-0.197496</td>\n",
       "      <td>0.207376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       x0  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0     1.0       0.013963         -0.008080     0.015547        0.219457   \n",
       "1     1.0      -0.053345          0.021332     0.003499       -0.073488   \n",
       "2     1.0       0.119732          0.001724     0.039644        0.007800   \n",
       "3     1.0       0.033193         -0.047295    -0.008549        0.032340   \n",
       "4     1.0       0.033193         -0.047295    -0.008549        0.032340   \n",
       "...   ...            ...               ...          ...             ...   \n",
       "4893  1.0      -0.062960         -0.066903    -0.026621       -0.073488   \n",
       "4894  1.0      -0.024499          0.040940     0.015547        0.024672   \n",
       "4895  1.0      -0.034114         -0.037491    -0.086862       -0.079623   \n",
       "4896  1.0      -0.130268          0.011528    -0.020597       -0.081157   \n",
       "4897  1.0      -0.082191         -0.066903     0.027595       -0.085758   \n",
       "\n",
       "      chlorides  free sulfur dioxide  total sulfur dioxide   density  \\\n",
       "0     -0.002292             0.033770              0.073409  0.134425   \n",
       "1      0.009578            -0.074244             -0.014758 -0.000528   \n",
       "2      0.012545            -0.018495             -0.095964  0.020679   \n",
       "3      0.036284             0.040738              0.110532  0.030319   \n",
       "4      0.036284             0.040738              0.110532  0.030319   \n",
       "...         ...                  ...                   ...       ...   \n",
       "4893  -0.020096            -0.039401             -0.107565 -0.055666   \n",
       "4894   0.003643             0.075582              0.068769  0.016823   \n",
       "4895  -0.014161            -0.018495             -0.063482 -0.028675   \n",
       "4896  -0.070541            -0.053338             -0.065802 -0.102899   \n",
       "4897  -0.076476            -0.046370             -0.093644 -0.089018   \n",
       "\n",
       "            pH  sulphates   alcohol  \n",
       "0    -0.171151  -0.046334 -0.276495  \n",
       "1     0.101576   0.000178 -0.163591  \n",
       "2     0.065212  -0.057961 -0.066817  \n",
       "3     0.001576  -0.104473 -0.099075  \n",
       "4     0.001576  -0.104473 -0.099075  \n",
       "...        ...        ...       ...  \n",
       "4893  0.074303   0.011806  0.110602  \n",
       "4894 -0.034788  -0.034706 -0.147462  \n",
       "4895 -0.180242  -0.034706 -0.179720  \n",
       "4896  0.137939  -0.127729  0.368667  \n",
       "4897  0.065212  -0.197496  0.207376  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 这里注意一个小trick：回归系数会比特征x多一维，为了向量相乘方便，可以在训练集X左侧添加全为1的一列\n",
    "# data0为处理好的所有列\n",
    "data0 = pd.concat([pd.DataFrame(np.ones(X.shape[0]), columns=['x0']), X], axis=1)\n",
    "data0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       6\n",
       "1       6\n",
       "2       6\n",
       "3       6\n",
       "4       6\n",
       "       ..\n",
       "4893    6\n",
       "4894    5\n",
       "4895    6\n",
       "4896    7\n",
       "4897    6\n",
       "Name: quality, Length: 4898, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.34805873],\n",
       "       [-0.86767146],\n",
       "       [-0.56041035],\n",
       "       [ 0.45150202],\n",
       "       [-1.85921895],\n",
       "       [-0.23864193],\n",
       "       [ 0.3221337 ],\n",
       "       [-0.7308419 ],\n",
       "       [ 0.5719634 ],\n",
       "       [ 0.52178761],\n",
       "       [ 0.53191578],\n",
       "       [-1.62061629]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化回归系数\n",
    "W_init = np.random.randn(data0.shape[1], 1)\n",
    "W_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO：批量梯度下降\n",
    "## TODO：随机梯度下降\n",
    "## TODO：回归模型在机器学习和统计学上的差异\n",
    "## TODO：岭回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       1.0\n",
       "       ... \n",
       "4893    1.0\n",
       "4894    1.0\n",
       "4895    1.0\n",
       "4896    1.0\n",
       "4897    1.0\n",
       "Name: x0, Length: 4898, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试内容\n",
    "data0['x0']\n",
    "# data0['x0'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.86767146])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试内容\n",
    "# data0['x0'][4]\n",
    "\n",
    "W_init[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基本要求\n",
    "\n",
    "将数据集winequality-white.csv按照4:1划分为训练集和测试集。  \n",
    "   1. 构造线性回归模型，并采用批量梯度下降和随机梯度下降进行优化；输出训练集和测试集的均方误差（MSE），画出MSE收敛曲线。       \n",
    "   2. 对于批量梯度下降和随机梯度下降，采用不同的学习率并进行MSE曲线展示，分析选择最佳的学习率。\n",
    "\n",
    "特别需要注意：\n",
    "   - 划分数据集时尽可能保持数据分布的一致性，保持样本类别比例相似，可采用分层采样的方式。\n",
    "   - 需要对数据集进行一定的预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 批量梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4:1划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: [251, 253, 294, 445, 740, 873, 1034, 1229, 1417, 1484, 1688, 1931, 2050, 2373, 3087, 3265, 3307, 3409, 3810, 4745], 4: [46, 98, 115, 147, 172, 176, 178, 189, 204, 207, 230, 250, 259, 278, 282, 433, 496, 499, 526, 540, 626, 641, 646, 659, 662, 687, 690, 702, 780, 831, 905, 906, 908, 914, 948, 991, 993, 1027, 1029, 1040, 1042, 1053, 1059, 1109, 1114, 1152, 1154, 1155, 1245, 1293, 1294, 1349, 1363, 1405, 1420, 1423, 1430, 1474, 1483, 1541, 1558, 1559, 1574, 1577, 1579, 1649, 1652, 1664, 1690, 1702, 1708, 1718, 1739, 1781, 1817, 1856, 1924, 1951, 1990, 2079, 2116, 2119, 2154, 2156, 2159, 2225, 2237, 2246, 2275, 2318, 2337, 2346, 2372, 2379, 2380, 2386, 2387, 2388, 2400, 2401, ...], 5: [10, 11, 12, 14, 19, 23, 34, 35, 36, 38, 39, 47, 49, 62, 65, 67, 69, 71, 72, 75, 78, 79, 82, 84, 88, 91, 100, 101, 102, 103, 104, 106, 109, 111, 112, 113, 114, 118, 119, 120, 121, 122, 126, 130, 132, 133, 134, 135, 137, 140, 141, 153, 161, 162, 164, 165, 168, 169, 174, 177, 181, 182, 184, 185, 187, 191, 193, 194, 196, 197, 198, 199, 200, 201, 202, 205, 206, 208, 210, 212, 215, 216, 217, 218, 219, 220, 225, 229, 240, 241, 244, 249, 252, 261, 262, 265, 267, 271, 272, 273, ...], 6: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 18, 24, 25, 26, 27, 28, 30, 31, 32, 33, 37, 40, 41, 42, 43, 44, 48, 50, 53, 54, 55, 56, 57, 58, 59, 60, 61, 63, 64, 70, 73, 80, 81, 83, 85, 86, 87, 89, 90, 95, 96, 99, 105, 107, 108, 110, 116, 117, 123, 124, 125, 129, 136, 139, 142, 143, 144, 145, 146, 149, 151, 152, 154, 155, 156, 163, 166, 170, 171, 175, 179, 180, 183, 186, 190, 192, 195, 203, 209, 213, 221, 223, 224, 226, 227, 228, 231, 232, 233, ...], 7: [13, 15, 21, 29, 45, 51, 52, 66, 76, 77, 92, 93, 94, 97, 127, 128, 131, 138, 148, 150, 157, 160, 167, 173, 211, 214, 222, 238, 242, 246, 247, 248, 256, 257, 279, 287, 288, 289, 290, 293, 297, 308, 310, 318, 320, 339, 340, 346, 350, 351, 353, 364, 365, 374, 375, 376, 377, 379, 380, 384, 385, 386, 389, 390, 406, 420, 424, 432, 435, 438, 440, 449, 452, 453, 454, 456, 473, 476, 491, 507, 509, 514, 548, 550, 551, 552, 553, 554, 555, 560, 563, 571, 573, 574, 577, 578, 579, 584, 587, 588, ...], 8: [17, 20, 22, 68, 74, 158, 159, 188, 255, 280, 281, 311, 330, 434, 437, 442, 598, 610, 625, 672, 723, 779, 783, 799, 832, 835, 836, 837, 838, 844, 845, 860, 867, 879, 904, 907, 924, 1022, 1086, 1087, 1095, 1106, 1115, 1136, 1137, 1187, 1216, 1218, 1219, 1266, 1283, 1306, 1333, 1336, 1344, 1345, 1348, 1358, 1402, 1403, 1406, 1412, 1464, 1493, 1494, 1504, 1619, 1632, 1665, 1715, 1723, 1778, 1779, 1797, 1980, 1981, 1982, 1983, 1984, 1991, 2298, 2333, 2342, 2382, 2384, 2389, 2390, 2522, 2525, 2663, 2748, 2750, 2753, 2774, 2775, 2776, 2795, 2803, 2804, 2857, ...], 9: [774, 820, 827, 876, 1605]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4:1划分训练集和测试集，这个操作对我是真的难！！！\n",
    "# x_train, x_test, y_train, y_test = train_test_split(dataset, y, test_size = 0.2) #划分训练集\n",
    "gbr = data.groupby('quality')  # 用分组函数groupby()进行数据的分组，分组依据为'TYPE'这一属性\n",
    "gbr.groups    # 获取分组后gbr的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "7\n",
      "-----------------------------------------------------\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "-----------------------------------------------------\n",
      "20\n",
      "163\n",
      "1457\n",
      "2198\n",
      "880\n",
      "175\n",
      "5\n",
      "-----------------------------------------------------\n",
      "4898\n",
      "[20, 163, 1457, 2198, 880, 175, 5]\n"
     ]
    }
   ],
   "source": [
    "# 划分各组长度，并将其存入数组\n",
    "print(len(gbr.groups[3]))\n",
    "print(len(gbr.groups))\n",
    "print('-----------------------------------------------------')\n",
    "for i in range(3, 10):\n",
    "    print(i)\n",
    "print('-----------------------------------------------------')\n",
    "    \n",
    "x = 0\n",
    "every_len = []\n",
    "\n",
    "for i in range(3, 10):\n",
    "    x += len(gbr.groups[i])\n",
    "    every_len.append(len(gbr.groups[i]))\n",
    "    print(len(gbr.groups[i]))\n",
    "    \n",
    "print('-----------------------------------------------------')\n",
    "    \n",
    "print(x)\n",
    "print(every_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  16  130 1166 1758  704  140    4]\n",
      "[  4  33 291 440 176  35   1]\n"
     ]
    }
   ],
   "source": [
    "train_rate = 0.8    # 所有数据中80%作为训练数据集，20%作为测试数据集\n",
    "num_tup = np.array(every_len)   # 全部数据中7种酒的质量的元组数\n",
    "num_train_tup = np.array([(int)(round(i*train_rate)) for i in num_tup])   # round函数对数进行四舍五入处理\n",
    "num_test_tup = num_tup - num_train_tup\n",
    "print(num_train_tup)\n",
    "print(num_test_tup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: 16, 4: 130, 5: 1166, 6: 1758, 7: 704, 8: 140, 9: 4}\n",
      "{3: 4, 4: 33, 5: 291, 6: 440, 7: 176, 8: 35, 9: 1}\n"
     ]
    }
   ],
   "source": [
    "# 定义分层抽样的字典，格式为：组名：数据个数\n",
    "typicalNDict_train = {3: num_train_tup[0], 4: num_train_tup[1], 5: num_train_tup[2], 6: num_train_tup[3],\n",
    "                      7: num_train_tup[4], 8: num_train_tup[5], 9: num_train_tup[6]}  # 此处要根据不同的地物类型的总数设置抽样的数据\n",
    "typicalNDict_test = {3: num_test_tup[0], 4: num_test_tup[1], 5: num_test_tup[2], 6: num_test_tup[3],\n",
    "                      7: num_test_tup[4], 8: num_test_tup[5], 9: num_test_tup[6]}  # 此处要根据不同的地物类型的总数设置抽样的数据\n",
    "print(typicalNDict_train)\n",
    "print(typicalNDict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 10, 19, 14, 6, 0, 7, 2, 3, 13, 5, 15, 9, 17, 4, 18]\n"
     ]
    }
   ],
   "source": [
    "# 测试随机生成数\n",
    "resultList=random.sample(range(0,20), 16)\n",
    "print(resultList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始生成训练集和测试集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数定义\n",
    "def typicalsamling(group, typicalNDict):\n",
    "    name = group.name\n",
    "    n = typicalNDict[name]\n",
    "    return group.sample(n=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
      "quality                                                                      \n",
      "3       1688            6.7              0.25         0.26            1.55   \n",
      "        251             8.5              0.26         0.21           16.20   \n",
      "        1229            8.3              0.33         0.42            1.15   \n",
      "        2373            7.6              0.48         0.37            1.20   \n",
      "        3409            6.2              0.23         0.35            0.70   \n",
      "...                     ...               ...          ...             ...   \n",
      "8       1336            7.8              0.29         0.36            7.00   \n",
      "9       820             6.6              0.36         0.29            1.60   \n",
      "        774             9.1              0.27         0.45           10.60   \n",
      "        876             6.9              0.36         0.34            4.20   \n",
      "        827             7.4              0.24         0.36            2.00   \n",
      "\n",
      "              chlorides  free sulfur dioxide  total sulfur dioxide  density  \\\n",
      "quality                                                                       \n",
      "3       1688      0.041                118.5                 216.0  0.99490   \n",
      "        251       0.074                 41.0                 197.0  0.99800   \n",
      "        1229      0.033                 18.0                  96.0  0.99110   \n",
      "        2373      0.034                  5.0                  57.0  0.99256   \n",
      "        3409      0.051                 24.0                 111.0  0.99160   \n",
      "...                 ...                  ...                   ...      ...   \n",
      "8       1336      0.042                 38.0                 161.0  0.99410   \n",
      "9       820       0.021                 24.0                  85.0  0.98965   \n",
      "        774       0.035                 28.0                 124.0  0.99700   \n",
      "        876       0.018                 57.0                 119.0  0.98980   \n",
      "        827       0.031                 27.0                 139.0  0.99055   \n",
      "\n",
      "                pH  sulphates  alcohol  quality  \n",
      "quality                                          \n",
      "3       1688  3.55       0.63      9.4        3  \n",
      "        251   3.02       0.50      9.8        3  \n",
      "        1229  3.20       0.32     12.4        3  \n",
      "        2373  3.05       0.54     10.4        3  \n",
      "        3409  3.37       0.43     11.0        3  \n",
      "...            ...        ...      ...      ...  \n",
      "8       1336  3.26       0.37     11.2        8  \n",
      "9       820   3.41       0.61     12.4        9  \n",
      "        774   3.20       0.46     10.4        9  \n",
      "        876   3.28       0.36     12.7        9  \n",
      "        827   3.28       0.48     12.5        9  \n",
      "\n",
      "[3918 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# 返回值：抽样后的训练数据框,此处抽取的是按照分层抽样的方法，抽取的80%的训练数据\n",
    "result_train = data.groupby('quality').apply(typicalsamling, typicalNDict_train)\n",
    "# print(result_train.head())\n",
    "print(result_train)\n",
    "# result_train.to_csv('csv_data/sample_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回值：抽样后的测试数据框,此处抽取的是按照分层抽样的方法，抽取的20%的测试数据，是随机抽取的数据，有可能与训练数据集有重复的数据\n",
    "# result_test1 = data.groupby('TYPE').apply(typicalsamling, typicalNDict_test)\n",
    "# print(result_test1.head())\n",
    "# result_test1.to_csv('csv_data/sample_test1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回值：抽样后的测试数据框，注意，此处是抽取完70%的训练数据之后，剩下的20%的数据，与训练集不会有重复的数据，该数据集带有分类的标签\n",
    "result_test_label = data.append(result_train).drop_duplicates(keep=False)   #此处是去重操作，用于去除重复的行，drop_duplicates()函数很有用\n",
    "print(result_test_label.head())\n",
    "result_test_label.to_csv('csv_data/sample_test_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#返回值：剩下的20%的数据，该数据集不带有分类的标签，专门用来验证的\n",
    "result_test = result_test_label.iloc[:, :-1]      #去除result_test_label中的最后一列，也就是去除标签列\n",
    "print(result_test.head())\n",
    "result_test_label.to_csv('csv_data/sample_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('训练数据集中每种样例的个数:\\n', result_train['TYPE'].value_counts())\n",
    "print('测试数据集中每种样例的个数:\\n', result_test_label['TYPE'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化\n",
    "def feature_scaling(x):\n",
    "    for i in range(len(x[0])):\n",
    "        max = -float('inf')\n",
    "        min = float('inf') \n",
    "        for m in range(len(x)):\n",
    "            if x[m][i] > max:\n",
    "                max = x[m][i]\n",
    "            if x[m][i] < min:\n",
    "                min = x[m][i]\n",
    "        for m in range(len(x)):\n",
    "            if max - min != 0:\n",
    "                x[m][i] = (x[m][i] - min) / (max - min)\n",
    "    return x\n",
    "x_train = feature_scaling(x_train)\n",
    "x_test = feature_scaling(x_test)\n",
    "# theta = np.random.rand(len(x_train[0]))\n",
    "# print(x_train[0])\n",
    "# print(theta)\n",
    "# print(theta * x_train)\n",
    "# print(x_train)\n",
    "# print(type(np.random.rand(len(x_train))))\n",
    "def gradient_descent(x_train, y_train, x_test, y_test, learning_rate):\n",
    "    loss = []\n",
    "    theta = np.random.rand(len(x_train[0]))\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    for index in range(1000):\n",
    "        gradients = x_train.T.dot(x_train.dot(theta) - y_train) / len(x_train)\n",
    "        theta = theta - learning_rate * gradients\n",
    "        MSE = ((np.dot(x_test, theta) - y_test) ** 2).sum() / len(x_test)\n",
    "        loss.append(MSE)\n",
    "    return theta, loss\n",
    "ls = []\n",
    "for i in range(1000):\n",
    "    ls.append(i)\n",
    "x = np.array(ls)\n",
    "theta0, loss0 = gradient_descent(x_train, y_train, x_train, y_train, learning_rate = 0.5)\n",
    "theta1, loss1 = gradient_descent(x_train, y_train, x_test, y_test, learning_rate = 0.5)\n",
    "theta2, loss2 = gradient_descent(x_train, y_train, x_test, y_test, learning_rate = 0.3)\n",
    "theta3, loss3 = gradient_descent(x_train, y_train, x_test, y_test, learning_rate = 0.1)\n",
    "theta4, loss4 = gradient_descent(x_train, y_train, x_test, y_test, learning_rate = 0.01)\n",
    "theta5, loss5 = gradient_descent(x_train, y_train, x_test, y_test, learning_rate = 0.001)\n",
    "# 画散点图\n",
    "colors0 = '#000000'\n",
    "colors1 = '#00CED1' #点的颜色\n",
    "colors2 = '#DC143C'\n",
    "colors3 = '#66CDAA'\n",
    "colors4 = '#BEBEBE'\n",
    "colors5 = '#00FA9A'\n",
    "area = np.pi * 0.5**2  # 点面积\n",
    "plt.scatter(x, loss0, s=area, c=colors0, alpha=0.4, label='train')\n",
    "plt.scatter(x, loss1, s=area, c=colors1, alpha=0.4, label='learning_rate = 0.5')\n",
    "plt.scatter(x, loss2, s=area, c=colors2, alpha=0.4, label='learning_rate = 0.3')\n",
    "# plt.scatter(x, loss3, s=area, c=colors3, alpha=0.4, label='learning_rate = 0.1')\n",
    "# plt.scatter(x, loss4, s=area, c=colors4, alpha=0.4, label='learning_rate = 0.01')\n",
    "# plt.scatter(x, loss5, s=area, c=colors5, alpha=0.4, label='learning_rate = 0.001')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 中级要求\n",
    "探究回归模型在机器学习和统计学上的差异。\n",
    "   - 回归模型在机器学习领域和统计学领域中都十分常用，而且使用方法也相似，但其实际的含义具有本质的区别。我们希望同学们从回归模型的角度更加充分地理解机器学习和统计学的区别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回归模型在机器学习和统计学上的差异\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验结果："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 高级要求\n",
    "编程实现岭回归算法，求解训练样本的岭回归模型，平均训练误差和平均测试误差（解析法、批量梯度下降法和随机梯度下降法均可）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 岭回归\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将手写体识别的留一法的上述所得到的结果用图片进行展示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次实验也到此结束🎉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结与展望"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 总结\n",
    "- 本次是机器学习的第一次实验，在做实验的过程中感受到了一些算法的强大，也通过手写留一法对交叉验证等课堂上所讲述的概念更加的熟悉\n",
    "- 然后再通过自己对weka工具的探索，虽然最后也没有找到和实现用java代码写，但是对之前上一学年所学习的java课也算有了一定的回顾\n",
    "- 最后通过使用weka工具成功对knn中k为1，3，5进行了实验，中间在文件格式转换方面也卡了一定的时间，但最后通过助教学长以及同学的帮助也顺利的解决了问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 展望\n",
    "通过第二次实验，发现自己对机器学习有了更近一步的认识，希望自己能在本学期的课程中学到更多，也希望自己未来能有更好的发展✌️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
